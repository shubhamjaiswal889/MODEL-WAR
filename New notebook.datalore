{"version":"1.0","data":{"sheets":[{"name":"Sheet","blocks":[{"type":"CODE","text":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"import os\nfor dirname, _, filenames in os.walk('\/data\/workspace_files\/healthcare-dataset-stroke-data.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"import pandas as pd\ndata = pd.read_csv(\"\/data\/workspace_files\/healthcare-dataset-stroke-data.csv\")\ndata.head()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>gender<\/th>\n      <th>age<\/th>\n      <th>hypertension<\/th>\n      <th>heart_disease<\/th>\n      <th>ever_married<\/th>\n      <th>work_type<\/th>\n      <th>Residence_type<\/th>\n      <th>avg_glucose_level<\/th>\n      <th>bmi<\/th>\n      <th>smoking_status<\/th>\n      <th>stroke<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>9046<\/td>\n      <td>Male<\/td>\n      <td>67.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>Yes<\/td>\n      <td>Private<\/td>\n      <td>Urban<\/td>\n      <td>228.69<\/td>\n      <td>36.6<\/td>\n      <td>formerly smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>51676<\/td>\n      <td>Female<\/td>\n      <td>61.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>Yes<\/td>\n      <td>Self-employed<\/td>\n      <td>Rural<\/td>\n      <td>202.21<\/td>\n      <td>NaN<\/td>\n      <td>never smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>31112<\/td>\n      <td>Male<\/td>\n      <td>80.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>Yes<\/td>\n      <td>Private<\/td>\n      <td>Rural<\/td>\n      <td>105.92<\/td>\n      <td>32.5<\/td>\n      <td>never smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>60182<\/td>\n      <td>Female<\/td>\n      <td>49.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>Yes<\/td>\n      <td>Private<\/td>\n      <td>Urban<\/td>\n      <td>171.23<\/td>\n      <td>34.4<\/td>\n      <td>smokes<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1665<\/td>\n      <td>Female<\/td>\n      <td>79.0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>Yes<\/td>\n      <td>Self-employed<\/td>\n      <td>Rural<\/td>\n      <td>174.12<\/td>\n      <td>24.0<\/td>\n      <td>never smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>","type":"html"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"data.isnull().sum()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"id                     0\ngender                 0\nage                    0\nhypertension           0\nheart_disease          0\never_married           0\nwork_type              0\nResidence_type         0\navg_glucose_level      0\nbmi                  201\nsmoking_status         0\nstroke                 0\ndtype: int64","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"data = data.fillna(0)","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"data.isnull().sum()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"id                   0\ngender               0\nage                  0\nhypertension         0\nheart_disease        0\never_married         0\nwork_type            0\nResidence_type       0\navg_glucose_level    0\nbmi                  0\nsmoking_status       0\nstroke               0\ndtype: int64","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"data.head()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>gender<\/th>\n      <th>age<\/th>\n      <th>hypertension<\/th>\n      <th>heart_disease<\/th>\n      <th>ever_married<\/th>\n      <th>work_type<\/th>\n      <th>Residence_type<\/th>\n      <th>avg_glucose_level<\/th>\n      <th>bmi<\/th>\n      <th>smoking_status<\/th>\n      <th>stroke<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>9046<\/td>\n      <td>Male<\/td>\n      <td>67.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>Yes<\/td>\n      <td>Private<\/td>\n      <td>Urban<\/td>\n      <td>228.69<\/td>\n      <td>36.6<\/td>\n      <td>formerly smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>51676<\/td>\n      <td>Female<\/td>\n      <td>61.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>Yes<\/td>\n      <td>Self-employed<\/td>\n      <td>Rural<\/td>\n      <td>202.21<\/td>\n      <td>0.0<\/td>\n      <td>never smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>31112<\/td>\n      <td>Male<\/td>\n      <td>80.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>Yes<\/td>\n      <td>Private<\/td>\n      <td>Rural<\/td>\n      <td>105.92<\/td>\n      <td>32.5<\/td>\n      <td>never smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>60182<\/td>\n      <td>Female<\/td>\n      <td>49.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>Yes<\/td>\n      <td>Private<\/td>\n      <td>Urban<\/td>\n      <td>171.23<\/td>\n      <td>34.4<\/td>\n      <td>smokes<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1665<\/td>\n      <td>Female<\/td>\n      <td>79.0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>Yes<\/td>\n      <td>Self-employed<\/td>\n      <td>Rural<\/td>\n      <td>174.12<\/td>\n      <td>24.0<\/td>\n      <td>never smoked<\/td>\n      <td>1<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>","type":"html"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"Gender = pd.get_dummies(data['gender'], drop_first=True)\nEver_Married = pd.get_dummies(data['ever_married'], drop_first=True)\nWork_Type = pd.get_dummies(data['work_type'], drop_first=True)\nresidence_type = pd.get_dummies(data['Residence_type'], drop_first=True)\nSmoking_Status = pd.get_dummies(data['smoking_status'], drop_first=True)\n\ndata = pd.concat([data,Gender,Ever_Married, Work_Type, residence_type, Smoking_Status],axis=1)\ndata = data.drop(['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis = 'columns')","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"data.head()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>age<\/th>\n      <th>hypertension<\/th>\n      <th>heart_disease<\/th>\n      <th>avg_glucose_level<\/th>\n      <th>bmi<\/th>\n      <th>stroke<\/th>\n      <th>Male<\/th>\n      <th>Other<\/th>\n      <th>Yes<\/th>\n      <th>Never_worked<\/th>\n      <th>Private<\/th>\n      <th>Self-employed<\/th>\n      <th>children<\/th>\n      <th>Urban<\/th>\n      <th>formerly smoked<\/th>\n      <th>never smoked<\/th>\n      <th>smokes<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>9046<\/td>\n      <td>67.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>228.69<\/td>\n      <td>36.6<\/td>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>51676<\/td>\n      <td>61.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>202.21<\/td>\n      <td>0.0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>31112<\/td>\n      <td>80.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>105.92<\/td>\n      <td>32.5<\/td>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>60182<\/td>\n      <td>49.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>171.23<\/td>\n      <td>34.4<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1665<\/td>\n      <td>79.0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>174.12<\/td>\n      <td>24.0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>","type":"html"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"X = data.drop('stroke', axis='columns')\ny = data.stroke","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"X.head()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>id<\/th>\n      <th>age<\/th>\n      <th>hypertension<\/th>\n      <th>heart_disease<\/th>\n      <th>avg_glucose_level<\/th>\n      <th>bmi<\/th>\n      <th>Male<\/th>\n      <th>Other<\/th>\n      <th>Yes<\/th>\n      <th>Never_worked<\/th>\n      <th>Private<\/th>\n      <th>Self-employed<\/th>\n      <th>children<\/th>\n      <th>Urban<\/th>\n      <th>formerly smoked<\/th>\n      <th>never smoked<\/th>\n      <th>smokes<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>9046<\/td>\n      <td>67.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>228.69<\/td>\n      <td>36.6<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>51676<\/td>\n      <td>61.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>202.21<\/td>\n      <td>0.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>31112<\/td>\n      <td>80.0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>105.92<\/td>\n      <td>32.5<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>60182<\/td>\n      <td>49.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>171.23<\/td>\n      <td>34.4<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>1665<\/td>\n      <td>79.0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>174.12<\/td>\n      <td>24.0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>","type":"html"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"y.head()","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"0    1\n1    1\n2    1\n3    1\n4    1\nName: stroke, dtype: int64","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nX_train.shape","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"(3577, 17)","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"X_test.shape","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nimport matplotlib.pyplot as plt","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"model = Sequential()\n# add first hidden layer with input diamension\nmodel.add(Dense(units = 32, activation='relu', kernel_initializer = 'he_uniform', input_dim = 17))\n# add second hidden layer\nmodel.add(Dense(units = 16, activation='relu', kernel_initializer = 'he_uniform'))\n# add output layer\nmodel.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer = 'glorot_uniform'))","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"# now we compile the model\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n# train the model\nmodel.fit(X_train, y_train, batch_size = 128, epochs = 50, verbose = 1)","outputs":[{"stdout":"Epoch 1\/50\n\r 1\/28 [>.............................] - ETA: 21s - loss: 281.1046 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 1s 2ms\/step - loss: 146.0215 - accuracy: 0.8864\nEpoch 2\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 79.0873 - accuracy: 0.9609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 78.0665 - accuracy: 0.9332\nEpoch 3\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 11.8944 - accuracy: 0.9219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 34.9528 - accuracy: 0.8937\nEpoch 4\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 1.8386 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 55.6312 - accuracy: 0.9531\nEpoch 5\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 9.3108 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 28.1351 - accuracy: 0.9202\nEpoch 6\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 39.5078 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 37.0690 - accuracy: 0.9178\nEpoch 7\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 9.2772 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 23.8061 - accuracy: 0.8764\nEpoch 8\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 33.0202 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/28 [=========================>....] - ETA: 0s - loss: 44.3764 - accuracy: 0.9319\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 44.3929 - accuracy: 0.9282\nEpoch 9\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 48.3095 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 41.5338 - accuracy: 0.9038\nEpoch 10\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 7.2249 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 9.8250 - accuracy: 0.8515\nEpoch 11\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 74.9901 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 50.7707 - accuracy: 0.9300\nEpoch 12\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 65.7200 - accuracy: 0.9219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/28 [===================>..........] - ETA: 0s - loss: 26.1908 - accuracy: 0.8593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 3ms\/step - loss: 21.5764 - accuracy: 0.8601\nEpoch 13\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 1.2076 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 20.8426 - accuracy: 0.9028\nEpoch 14\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 63.4829 - accuracy: 0.0469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 43.9761 - accuracy: 0.8042\nEpoch 15\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 106.4644 - accuracy: 0.9219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 57.1990 - accuracy: 0.9214\nEpoch 16\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 72.5488 - accuracy: 0.9297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 32.2690 - accuracy: 0.8856\nEpoch 17\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 77.7045 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 66.7563 - accuracy: 0.9367\nEpoch 18\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 66.1604 - accuracy: 0.9219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 39.5819 - accuracy: 0.8933\nEpoch 19\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 41.4821 - accuracy: 0.9219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 35.2998 - accuracy: 0.8811\nEpoch 20\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 5.4369 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 33.7539 - accuracy: 0.8302\nEpoch 21\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 49.4845 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 36.4272 - accuracy: 0.9150\nEpoch 22\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 26.6548 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 18.6023 - accuracy: 0.9031\nEpoch 23\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 29.8629 - accuracy: 0.9609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 33.3179 - accuracy: 0.9145\nEpoch 24\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 5.4185 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 13.2772 - accuracy: 0.9235\nEpoch 25\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 7.1384 - accuracy: 0.9844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 24.6566 - accuracy: 0.9168\nEpoch 26\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 56.1640 - accuracy: 0.9141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 29.8350 - accuracy: 0.8833\nEpoch 27\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 6.1001 - accuracy: 0.9844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 25.5843 - accuracy: 0.9113\nEpoch 28\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 20.6984 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 28.2847 - accuracy: 0.8752\nEpoch 29\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 48.1044 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 61.0992 - accuracy: 0.9442\nEpoch 30\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 22.8498 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/28 [==================>...........] - ETA: 0s - loss: 30.4372 - accuracy: 0.9251\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 3ms\/step - loss: 32.7817 - accuracy: 0.9167\nEpoch 31\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 61.5406 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/28 [=====================>........] - ETA: 0s - loss: 38.8129 - accuracy: 0.8948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 39.2189 - accuracy: 0.9005\nEpoch 32\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 4.6838 - accuracy: 0.9219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 1ms\/step - loss: 26.3157 - accuracy: 0.8446\nEpoch 33\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 45.2532 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 47.9561 - accuracy: 0.9216\nEpoch 34\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 59.4850 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 34.4769 - accuracy: 0.9216\nEpoch 35\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 18.8616 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 28.0594 - accuracy: 0.8768\nEpoch 36\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 35.1172 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 40.1176 - accuracy: 0.9260\nEpoch 37\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 61.8950 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 36.5799 - accuracy: 0.9142\nEpoch 38\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 42.9154 - accuracy: 0.9141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 31.5383 - accuracy: 0.8655\nEpoch 39\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 9.5528 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 29.6694 - accuracy: 0.9394\nEpoch 40\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 80.4945 - accuracy: 0.9141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 43.0545 - accuracy: 0.9121\nEpoch 41\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 31.7830 - accuracy: 0.9297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 32.1971 - accuracy: 0.8859\nEpoch 42\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 18.0257 - accuracy: 0.9453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 25.7964 - accuracy: 0.8442\nEpoch 43\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 43.0763 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 57.7513 - accuracy: 0.9327\nEpoch 44\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 35.8560 - accuracy: 0.9609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 36.1684 - accuracy: 0.8992\nEpoch 45\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 45.5365 - accuracy: 0.9141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 35.6888 - accuracy: 0.8862\nEpoch 46\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 51.7840 - accuracy: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 34.1113 - accuracy: 0.8022\nEpoch 47\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 25.7746 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 52.9209 - accuracy: 0.9294\nEpoch 48\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 63.0114 - accuracy: 0.9297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 37.1582 - accuracy: 0.9023\nEpoch 49\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 31.0447 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 33.1725 - accuracy: 0.8736\nEpoch 50\/50\n\r 1\/28 [>.............................] - ETA: 0s - loss: 6.1763 - accuracy: 0.7109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/28 [==============================] - 0s 2ms\/step - loss: 5.0375 - accuracy: 0.8475\n","stderr":"","outputReprs":[],"displayData":[{"text":"<tensorflow.python.keras.callbacks.History at 0x7f14d6f4f580>","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"acc = model.evaluate(X_test, y_test)","outputs":[{"stdout":"\r 1\/48 [..............................] - ETA: 14s - loss: 11.4389 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/48 [=======>......................] - ETA: 0s - loss: 5.9211 - accuracy: 0.8795  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48\/48 [==============================] - 0s 2ms\/step - loss: 6.0549 - accuracy: 0.8878\n","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"model.summary()","outputs":[{"stdout":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 32)                576       \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 1,121\nTrainable params: 1,121\nNon-trainable params: 0\n_________________________________________________________________\n","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"y_ann = model.predict(X_test)\ny_ann = y_ann > 0.5","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_ann, y_test)\ncm","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"array([[1349,   63],\n       [ 109,   12]])","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"MD","text":"Support Vector Machine","outputs":[],"language":"MARKDOWN","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nmodel_svm = SVC()\nmodel_svm.fit(X_train, y_train)\ny_svm = model_svm.predict(X_test)\nacc_svm = accuracy_score(y_svm, y_test)\ncm_svm = confusion_matrix(y_svm, y_test)\nacc_svm","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"0.9510763209393346","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"cm_svm","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"array([[1458,   75],\n       [   0,    0]])","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"from sklearn.metrics import classification_report\nprint(classification_report(y_svm, y_test))","outputs":[{"stdout":"              precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97      1533\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.95      1533\n   macro avg       0.50      0.48      0.49      1533\nweighted avg       1.00      0.95      0.97      1533\n\n","stderr":"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/metrics\/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/metrics\/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/metrics\/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"MD","text":"**Random ****Forest**","outputs":[],"language":"MARKDOWN","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"from sklearn.ensemble import RandomForestClassifier\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X_train, y_train)\ny_rf = model_rf.predict(X_test)\nacc_rf = accuracy_score(y_rf, y_test)\ncm_rf = confusion_matrix(y_rf, y_test)\nacc_rf","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"0.9504240052185258","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"cm_rf","outputs":[{"stdout":"","stderr":"","outputReprs":[],"displayData":[{"text":"array([[1454,   72],\n       [   4,    3]])","type":"text"}]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"from sklearn.metrics import classification_report\nprint(classification_report(y_rf, y_test))","outputs":[{"stdout":"              precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97      1526\n           1       0.04      0.43      0.07         7\n\n    accuracy                           0.95      1533\n   macro avg       0.52      0.69      0.52      1533\nweighted avg       0.99      0.95      0.97      1533\n\n","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"print(\"Artificial Neural Network Accuracy : \", acc)\nprint(\"Support Vector Machine Accuracy : \", acc_svm)\nprint(\"Random Forest Accuracy : \", acc_rf)","outputs":[{"stdout":"Artificial Neural Network Accuracy :  [6.054936408996582, 0.8878017067909241]\nSupport Vector Machine Accuracy :  0.9510763209393346\nRandom Forest Accuracy :  0.9504240052185258\n","stderr":"","outputReprs":[],"displayData":[]}],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true},{"type":"CODE","text":"","outputs":[],"language":"PYTHON","inputCollapsed":false,"outputCollapsed":true}]}],"packages":[{"name":"keras","source":"PIP"}],"kernelType":"IPYTHON","language":"PYTHON"}}